---
title: "Ass 3"
author: "Nyasha"
date: "7/2/2020"
output: pdf_document
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(FactoMineR)) install.packages("FactoMineR", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(plotly)) install.packages("plotly", repos = "http://cran.us.r-project.org")
if(!require(gbm)) install.packages("gbm", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(formattable)) install.packages("formattable", repos = "http://cran.us.r-project.org")
if(!require(naniar)) install.packages("naniar", repos = "http://cran.us.r-project.org")
if(!require(rattle)) install.packages("rattle", repos = "http://cran.us.r-project.org")
if(!require(shinythemes)) install.packages("shinythemes", repos = "http://cran.us.r-project.org")
if(!require(pROC)) install.packages("pROC", repos = "http://cran.us.r-project.org")
if(!require(rAverage)) install.packages("rAverage", repos = "http://cran.us.r-project.org")
if(!require(caTools)) install.packages("caTools", repos = "http://cran.us.r-project.org")
if(!require(glmnet)) install.packages("glmnet", repos = "http://cran.us.r-project.org")
library(knitr)
if(!require(cowplot)) install.packages("cowplot", repos = "http://cran.us.r-project.org")
if(!require(ROCR)) install.packages("ROCR", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(e1071)) install.packages("e1071", repos = "http://cran.us.r-project.org")
if(!require(neuralnet)) install.packages("neuralnet", repos = "http://cran.us.r-project.org")
if(!require(readxl)) install.packages("readxl", repos = "http://cran.us.r-project.org")
if(!require(h2o)) install.packages("h2o", repos = "http://cran.us.r-project.org")
```

# Exploratory Data Analysis


```{r}
framingham.assignment
sum(is.na(framingham.assignment))

# male, education, currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, traintest, TenYearCHD should be factors

framingham.assignment$male <- as.factor(framingham.assignment$male)
framingham.assignment$education <- as.factor(framingham.assignment$education)
framingham.assignment$currentSmoker <- as.factor(framingham.assignment$currentSmoker)
framingham.assignment$BPMeds <- as.factor(framingham.assignment$BPMeds)
framingham.assignment$prevalentStroke <- as.factor(framingham.assignment$prevalentStroke)
framingham.assignment$prevalentHyp <- as.factor(framingham.assignment$prevalentHyp)
framingham.assignment$diabetes <- as.factor(framingham.assignment$diabetes)
framingham.assignment$traintest <- as.factor(framingham.assignment$traintest)
framingham.assignment$TenYearCHD <- as.factor(framingham.assignment$TenYearCHD)
# framingham.assignment$ <- as.factor(framingham.assignment$ )

str(framingham.assignment)

df1 <- framingham.assignment

unique(df1$cigsPerDay)

df1.st <- cbind(scale(df1[,c(2,5,10, 11, 12, 13, 14, 15)]), df1[,c(-2,-5,-10, -11, -12, -13, -14, -15)])

train <- filter(df1.st, traintest == "1")
test <- filter(df1.st, traintest == "0")

train <- select(train, -"traintest")
test <- select(test, -"traintest")

sum(is.na(train))
sum(is.na(test))

vis_miss(train)



```



```{r}
set.seed(1)
samp <- createDataPartition(train$TenYearCHD, times = 1, p = 0.8)

train_1 <- train[samp[["Resample1"]],]
validation <- train[-samp[["Resample1"]],]

vis_miss(train_1)
vis_miss(validation)


#
train_1 <- train_1 %>% drop_na()
validation <- validation %>% drop_na()


vis_miss(train_1)
vis_miss(validation)


```

```{r}

cor(train_1[,c(1:8)])
corrplot(train_1)
model1

```


## Variable selection

```{r}

mod <- glm(TenYearCHD~.,data = train_1, family = binomial)
s1 <- summary(mod)
s1



train_a <- na.omit(train_1)
X <- data.matrix(train_a[,c(-16)])
Y <- data.matrix(train_a[16])

set.seed(1)
mod_a <- glmnet(X, Y, alpha = 1, nfolds = 10, type.measure = 'class', family = 'binomial')
set.seed(1)
cv <- cv.glmnet(X, Y, alpha = 1, nfolds = 10, type.measure = 'class', standardize = T, family = 'binomial')
plot(cv)

c1 <- coef(mod_a, s=cv$lambda.1se)
c2 <- coef(mod_a, s=cv$lambda.min)

mod_b <- glmnet(X, Y, alpha = 0.5, nfolds = 10, type.measure = 'class', family = 'binomial')
set.seed(1)
cv <- cv.glmnet(X, Y, alpha = 0.5, nfolds = 10, type.measure = 'class', standardize = T, family = 'binomial')
plot(cv)

(c3 <- coef(mod_b, s=cv$lambda.1se))
(c4 <- coef(mod_b, s=cv$lambda.min))


```

The general logistic regression model shows that age, cigsPerDay, sysBP, glucose and gender(male) are significant variables.

The Lasso regression model uses age, cigsPerDay, sysBP, glucose, gender(male), education, prevalentStroke, prevalentHyp and diabetes as the variables.

Elastic net model uses age, cigsPerDay, SysBP, diaBP, heartRate, glucose, male, education, PrevalentStroke, prevalentHyp, diabetes

## Facts 

All the three models use age, cigsPerDay, sysBP, glucose, gender(male)




## Support Vector Machines

```{r}

# 1 linear
svm_model = svm(TenYearCHD ~. ,
                data = train_1,
                type = 'C-classification',
                kernel = "linear",
                scale = FALSE,
                cost = 1)
svm_model

svm_pred = predict(svm_model, train_1)
mean(svm_pred == train_1$TenYearCHD)

svm_pred1 = predict(svm_model, validation)
mean(svm_pred1 == validation$TenYearCHD)

# 2 radial
svm_model = svm(TenYearCHD ~. ,
                data = train_1,
                type = 'C-classification',
                kernel = "radial",
                scale = FALSE,
                cost = 1)
svm_model

svm_pred = predict(svm_model, train_1)
mean(svm_pred == train_1$TenYearCHD)

svm_pred1 = predict(svm_model, validation)
mean(svm_pred1 == validation$TenYearCHD)


# 3 polynomial
svm_model = svm(TenYearCHD ~. ,
                data = train_1,
                type = 'C-classification',
                kernel = "polynomial",
                scale = FALSE,
                cost = 1)
svm_model

svm_pred = predict(svm_model, train_1)
mean(svm_pred == train_1$TenYearCHD)

svm_pred1 = predict(svm_model, validation)
mean(svm_pred1 == validation$TenYearCHD)


# 4 sigmoid
svm_model = svm(TenYearCHD ~. ,
                data = train_1,
                type = 'C-classification',
                kernel = "sigmoid",
                scale = FALSE,
                cost = 1)
svm_model

svm_pred = predict(svm_model, train_1)
mean(svm_pred == train_1$TenYearCHD)

svm_pred1 = predict(svm_model, validation)
mean(svm_pred1 == validation$TenYearCHD)



## Not much change when you change kernel function

set.seed(1)
tunesvm = tune.svm(TenYearCHD~. ,
                   data = train_1,
                   type = 'C-classification',
                   kernel = c("radial"),
                   cost=seq(from=0.1, to=1 ,by=0.2))

tunesvm
bestmodel_all = tunesvm$best.model
save(bestmodel_all, file = "bestmodel_all.rda")
bestmodel_all

svm_pred1 = predict(bestmodel_all, validation)
mean(svm_pred1 == validation$TenYearCHD)
# 0.8431034

## Lasso
set.seed(1)
tunesvm = tune.svm(TenYearCHD~. ,
                   data = train_1[,c(1,2,4,8,9,10,13:16)],
                   type = 'C-classification',
                   kernel = c("radial"),
                   cost=seq(from=0.1, to=1 ,by=0.2))

tunesvm
bestmodel_lasso = tunesvm$best.model
bestmodel_lasso

save(bestmodel_lasso, file = "bestmodel_lasso.rda")

svm_pred1 = predict(bestmodel_lasso, validation)
mean(svm_pred1 == validation$TenYearCHD)
# 0.8431034

## Log reg
set.seed(1)
tunesvm = tune.svm(TenYearCHD~. ,
                   data = train_1[,c(1,2,4,8,9,10,16)],
                   type = 'C-classification',
                   kernel = c("radial"),
                   cost=seq(from=0.1, to=1 ,by=0.2))

tunesvm
bestmodel_log_reg = tunesvm$best.model
bestmodel_log_reg
save(bestmodel_log_reg, file = "bestmodel_log_reg.rda")

svm_pred1 = predict(bestmodel_log_reg, validation)
mean(svm_pred1 == validation$TenYearCHD)
# 0.8431034

## Elastic net
set.seed(1)
tunesvm = tune.svm(TenYearCHD~. ,
                   data = train_1[,c(1,2,4,5,7,8,9,10, 13:16)],
                   type = 'C-classification',
                   kernel = c("radial"),
                   cost=seq(from=0.1, to=1 ,by=0.2))

tunesvm
bestmodel_elastic = tunesvm$best.model
bestmodel_elastic
save(bestmodel_elastic, file = "bestmodel_elastic.rda")

svm_pred1 = predict(bestmodel_elastic, validation)
mean(svm_pred1 == validation$TenYearCHD)
#  0.8396552


```





```{r}
# pca <- PCA(train_1, ncp=5, graph=T)
# dimdesc(pca)
```

Look at correlation matrix
Use PCA and other variable selection techniques

Testing begins with a single layer, then add hidden layers to check if the model is improved in any way

```{r}

# The general logistic regression model shows that age, cigsPerDay, sysBP, glucose and gender(male) are significant variables.
# 
# The Lasso regression model uses age, cigsPerDay, sysBP, glucose, gender(male), education, prevalentStroke, prevalentHyp and diabetes as the variables.
# 
# Elastic net model uses age, cigsPerDay, SysBP, diaBP, heartRate, glucose, male, education, PrevalentStroke, prevalentHyp, diabetes
# 

#localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,min_mem_size = "1g")
localH2O = h2o.init()
train.h2o <- as.h2o(train_1)
test.h2o <- as.h2o(validation)

hidden_opt <- list(c(2), c(3), c(4), c(5), c(3,3), c(5,5))
act <- c("Tanh", "Rectifier" )
l1_opt <- c(1e-5, 1e-7)
hyper_params <- list(hidden = hidden_opt, l1 = l1_opt, activation = act)


## Lasso model
set.seed(1)
model_grid <- h2o.grid(
  "deeplearning",
  hyper_params = hyper_params,
  x = c(1,2,4,8,9,10,13:15),
  y = 16,
  seed = 1, 
  reproducible = TRUE,
  distribution = "AUTO",
  balance_classes = TRUE,
  training_frame = train.h2o,
  validation_frame = test.h2o, 
  nfolds=10)

model_grid
model_lasso = h2o.getModel(model_grid@model_ids[[1]])
save(model_lasso, file = "model_lasso.rda")

c <- h2o.predict(model_lasso , test.h2o)
yhat = as.factor(as.matrix(c$predict))
confusionMatrix(yhat, validation$TenYearCHD)
# 0.7966 

## logistic regression model
set.seed(1)
model_grid <- h2o.grid(
  "deeplearning",
  hyper_params = hyper_params,
  x = c(1,2,4,8,9,10),
  y = 16,
  seed = 1, 
  reproducible = TRUE,
  distribution = "AUTO",
  balance_classes = TRUE,
  training_frame = train.h2o,
  validation_frame = test.h2o, nfolds=10)

model_grid
model_glm = h2o.getModel(model_grid@model_ids[[1]])
save(model_glm, file = "model_glm.rda")

c <- h2o.predict(model_glm , test.h2o)
yhat = as.factor(as.matrix(c$predict))
confusionMatrix(yhat, validation$TenYearCHD)
# 0.8103

## elastic net model
set.seed(1)
model_grid <- h2o.grid(
  "deeplearning",
  hyper_params = hyper_params,
  x = c(1,2,4,5,7,8,9,10, 13:15),
  y = 16,
  seed = 1, 
  reproducible = TRUE,
  distribution = "AUTO",
  balance_classes = TRUE,
  training_frame = train.h2o,
  validation_frame = test.h2o, nfolds=10)

model_grid
model_elastic = h2o.getModel(model_grid@model_ids[[1]])
save(model_elastic, file = "model_elastic.rda")

c <- h2o.predict(model_elastic , test.h2o)
yhat = as.factor(as.matrix(c$predict))
confusionMatrix(yhat, validation$TenYearCHD)
# 0.7638

```